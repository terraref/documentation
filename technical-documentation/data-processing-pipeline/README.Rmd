# Data Processing Pipeline

![](../../.gitbook/assets/pipeline.jpg)

## Maricopa Agricultural Center, Arizona

## Automated controlled-environment phenotyping, Missouri

![](../../.gitbook/assets/terraref-danforth-pipline-v3.jpg)

At two points in the processing pipeline, metadata derived from collected data is inserted into BETYdb:

* At the start of the transfer process, metadata collected and derived during Danforth's initial processing will be pushed.
* After transfer to NCSA, extractors running in Clowder will derive further metadata that will be pushed. This is a subset of the metadata that will also be stored in Clowder's database. The complete metadata definitions are still being determined, but will likely include:
  * plant identifiers
  * experiment and experimenter
  * plant age, date, growth medium, and treatment
  * camera metadata

## Kansas State University

## HudsonAlpha - Genomics

